---
title: "Untitled"
output: html_document
---


## Testowanie hipotez statystycznych 

Jak pamiętamy, statystyka częstościowa opiera się na testowaniu hipotezy zerowej. Hipotezą zerową zwykle jest model, który świadczy o braku efektu, na przykad, że różnica średnich wynosi lub współczynnik regresji wynosi 0. Im mniejsza p-value, tym bardziej otrzymane dane nie pasują to tego modelu. Jeśli jednak p-value jest większa niż 0.05 nie oznacza to, że model zerowy jest **bardziej prawdopodobny** niż inne. Innymi słowy, ten rodzaj testowania może nam jedynie powiedzieć o występowaniu różnicy średnich czy występowaniu korelacji, ale nie o jej braku. 

Przypomnijmy sobie, że wielkość przedziału ufności dla testu zależy od wariancji i wielkości próby. Gdyby NHST pozwalało nam orzekać o równości średnich, udowodnienie takiej hipotezy byłoby niezwykle łatwe.

Na przykład załóżmy, że chcemy sprawdzić czy nowy lek nie różni się skutecznością od leku będącego już na rynku. Wystarczyłoby manipulować wielkoscią próby, by otrzymać wniosek o braku istotnej różnicy pomiędzy wpływem tych dwóch leków!

Dlatego chcielibyśmy móc orzec, który z modeli (hiptez) jest bardziej prawdopodobny. Podejście bayesowskie daje nam taką możliwość. 


### Czynnik Bayesowski

Czym jest model? **Najprościej mówiąc model jest zbiorem ograniczeń, który nakładamy na proces generujący dane.** Na przykład może interesować nas porównanie dwóch różnych modeli regresji z innymi zbiorami predyktorów. Przykładowy model $M_i$ posiada parametry $\theta$ i funkcje wiarygodnośći $P(D \mid \theta, M)$. Załóżmy, że chcielibyśmy policzyć prawodpodbieństwo *a posteriori* modelu $P(M \mid D)$.
 
$$P(M_i \mid D) = \frac{ P(D \mid M_i) \ P(M_i) }{\int P(D \mid M) \ P(M) \  \text{d} M}\,$$ 
Widzimy, że analogicznie jak w poprzednich częściach tutoriala za pomocą twierdzenia Bayesa,  interesuje nas obliczenie prawdopodobieństwa modelu $M_i$ pod warunkiem otrzymanych przez nas danych. 

Prawdopodobieństwo $P(M_1)$ jest oczywiście prawdopdobieństwem *a priori* naszego modelu. Sami je ustlamy, więc nie ma z nim problemu.

Nasuwa się jednak pytanie jak obliczyć funkcję wiarygodności? $P(D|M_1)$ oznacza prawdopodbieństwo danych pod warunkiem modelu dla wszystkich możliwych wartości parametrów:

$$P(D \mid M_i) = \int P(D \mid \theta, M_i) \ P(\theta \mid M_i) \ \text{d}\theta$$

Co to znaczy dla wszystkich możliwych parametrów? Załóżmy, że mamy dwa modele regresji liniowej, różniące się tym, że jeden ma dodatkowy predyktor. Tak jak pisałem wcześniej w statystyce bayesowksiej nie otrzymamy punktowych estymat parametrów $\theta$, ale ich rozkłady $P(\theta|y)$. Ponieważ jednak, chcemy otrzymać jedną wartość - prawdopodobieństwo naszego modelu **dla wszystkich możliwych wartości parametrów**, całkujemy po parametrach, by pozbyć się $\theta$ z równania.  
 
Teraz zerknijmy na mianownik naszego rówanania zawierający $P(D) = \int P(D \mid M) \ P(M) \  \text{d} M$. Tutaj sprawa się komplikuje, ponieważ by obliczyć $P(D)$ musielibyśmy całkować po wszystkich (nieskończenie wielu) możliwych modelach. Jego obliczenie jest w zasadzie niemożliwe zarówno analitycznie (jak wyznaczyć rozkład $P(M)$, dla wszystkich możliwych modeli), jak i numerycznie (ponieważ musielibyśmy wymyślić i policzyć te wszystkie modele).

A co jeśli porównamy dwa modele ze sobą?

$$ \underbrace{{\frac{P(M_1|D)}{P(M_2|D)}}}_{\text{stosunek a posteriori}} = \frac{\frac{P(D|M_1)P(M_1)}{P(D)}}{\frac{P(D|M_2)P(M_2)}{P(D)}} = \underbrace{\frac{P(D|M_1)}{P(D|M_2)}}_{\text{czynnik bayesowski}} * \underbrace{\frac{P(M_1)}{P(M_2)}}_{\text{stosunek a prior}}$$
 
Robiąc tak, pozbywamy się konieczności obliczania $P(D)$! 

Jednak oceniając modele nie używamy stosunku prawdopobieństw *posteriori* , lecz stosunku funkcji wiargodności nazywanym **Czynnikiem Bayesowskim**:

$$BF_{12} = \frac{P(D|M_1)}{P(D|M_2)}$$
Jest tak dlatego, że stosunek prawdopodbieństw *a posteriori* zależy od danych, ale także od prawdopdobieństw *a priori* modeli. Manipulując nimi, moglibyśmy zawsze uzyskać miarę faworyzującą nasz model. Użycie stosunku funkcji wiarygodności, mówi nam o ile bardziej/mniej prawdopodobne jest, że $M_1$ wyprodukował obserwowane dane od $M_2$. Ponadto jeśli przepiszemy wzór na stosunek *a posteriori*, uzyskamy 

$$ \underbrace{\frac{P(D|M_1)}{P(D|M_2)}}_{BF_{12}} = \underbrace{\frac{P(M_1|D)}{P(M_2|D)}}_{\text{stosunek posteriori }}:\underbrace{\frac{P(M_1)}{P(M_2)}}_{\text{stosunek a priori}}$$

Co daje nam dodatkową interpretację czynnika Bayesowskiego. Jest on stosunkiem prawdopodobieństw *posteriori* podzielony przez stosunek prawdopodobieństw *a priori* naszych dwóch modeli. Mówi nam **o ile zmieniły się nasze przekonania *a prior* po zobaczeniu danych**. Innymi słowy, Czynnik Bayesowski mówi nam jak zmieniły się pod wpływem danych nasze początkowe przekonania co do tego, który model jest lepszy.




